geom_vline(aes(xintercept = mean(df$Solids,na.rm = T), color ="mean")) +
geom_vline(aes(xintercept = 500, color ="WHO recommendation")) +
geom_vline(aes(xintercept = 1000, color ="WHO recommendation")) +
scale_color_manual(values = c("red","blue", "black"))  +
theme_ipsum() +
labs(fill="Quality of the water", title= "Distribution of Solids for potable and non-potable water", color = "Mean and median")
ggplot(df, aes(x=Chloramines, fill=factor(Potability))) +
geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "#404080"), labels = c("Non-potable","Potable")) +
geom_vline(aes(xintercept = median(df$Chloramines, na.rm=T), color="median")) +
geom_vline(aes(xintercept = mean(df$Chloramines,na.rm = T), color ="mean")) +
geom_vline(aes(xintercept = 0, color ="WHO recommendation")) +
geom_vline(aes(xintercept = 4, color ="WHO recommendation")) +
scale_color_manual(values = c("red","blue","black"))  +
theme_ipsum() +
labs(fill="Quality of the water", title= "Distribution of Chloramines for potable and non-potable water", color = "Mean and median")
ggplot(df, aes(x=Sulfate, fill=factor(Potability))) +
geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "#404080"), labels = c("Non-potable","Potable")) +
geom_vline(aes(xintercept = median(df$Sulfate, na.rm=T), color="median")) +
geom_vline(aes(xintercept = mean(df$Sulfate,na.rm = T), color ="mean")) +
scale_color_manual(values = c("red","blue"))  +
theme_ipsum() +
labs(fill="Quality of the water", title= "Distribution of Sulfate for potable and non-potable water", color = "Mean and median")
ggplot(df, aes(x=Conductivity, fill=factor(Potability))) +
geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "#404080"), labels = c("Non-potable","Potable")) +
geom_vline(aes(xintercept = median(df$Conductivity, na.rm=T), color="median")) +
geom_vline(aes(xintercept = mean(df$Conductivity,na.rm = T), color ="mean")) +
geom_vline(aes(xintercept = 0, color ="WHO recommendation")) +
geom_vline(aes(xintercept = 400, color ="WHO recommendation")) +
scale_color_manual(values = c("red","blue", "black"))  +
theme_ipsum() +
labs(fill="Quality of the water", title= "Distribution of Conductivity for potable and non-potable water", color = "Mean and median")
ggplot(df, aes(x=Organic_carbon, fill=factor(Potability))) +
geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "#404080"), labels = c("Non-potable","Potable")) +
geom_vline(aes(xintercept = median(df$Organic_carbon, na.rm=T), color="median")) +
geom_vline(aes(xintercept = mean(df$Organic_carbon,na.rm = T), color ="mean")) +
geom_vline(aes(xintercept = 2, color ="Recommendation")) +
scale_color_manual(values = c("red","blue", "black"))  +
theme_ipsum() +
labs(fill="Quality of the water", title= "Distribution of Organic carbon for potable and non-potable water", color = "Mean and median")
ggplot(df, aes(x=Trihalomethanes, fill=factor(Potability))) +
geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "#404080"), labels = c("Non-potable","Potable")) +
geom_vline(aes(xintercept = median(df$Trihalomethanes, na.rm=T), color="median")) +
geom_vline(aes(xintercept = mean(df$Trihalomethanes,na.rm = T), color ="mean")) +
geom_vline(aes(xintercept = 0, color ="WHO recommendation")) +
geom_vline(aes(xintercept = 80, color ="WHO recommendation")) +
scale_color_manual(values = c("red","blue","black"))  +
theme_ipsum() +
labs(fill="Quality of the water", title= "Distribution of Trihalomethanes for potable and non-potable water", color = "Mean and median")
ggplot(df, aes(x=Turbidity, fill=factor(Potability))) +
geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "#404080"), labels = c("Non-potable","Potable")) +
geom_vline(aes(xintercept = median(df$Turbidity, na.rm=T), color="median")) +
geom_vline(aes(xintercept = mean(df$Turbidity,na.rm = T), color ="mean")) +
geom_vline(aes(xintercept = 0, color ="WHO recommendation")) +
geom_vline(aes(xintercept = 5, color ="WHO recommendation")) +
scale_color_manual(values = c("red","blue","black"))  +
theme_ipsum() +
labs(fill="Quality of the water", title= "Distribution of Turbidity for potable and non-potable water", color = "Mean and median")
par(mfrow=c(1,2))
df_1 = df[df$Potability == 1,]
df_0 = df[df$Potability == 0,]
#### to to put max min and the value
rad_1 = data.frame(ph = c(max(df_1$ph, na.rm = T),0,mean(df_1$ph, na.rm=T)),
Hardness = c(max(df_1$Hardness),0,mean(df_1$Hardness, na.rm=T)),
Solids = c(max(df_1$Solids),0,mean(df_1$Solids, na.rm=T)),
Chloramines = c(max(df_1$Chloramines),0,mean(df_1$Chloramines, na.rm=T)),
Sulfate = c(max(df_1$Sulfate, na.rm = T),0,mean(df_1$Sulfate, na.rm=T)),
Conductivity = c(max(df_1$Conductivity),0,mean(df_1$Conductivity, na.rm=T)),
Organic_Carbon = c(max(df_1$Organic_carbon),0,mean(df_1$Organic_carbon, na.rm=T)),
Trihalomethanes = c(max(df_1$Trihalomethanes,na.rm=T),0,mean(df_1$Trihalomethanes, na.rm=T)),
Turbidity = c(max(df_1$Turbidity),0,mean(df_1$Turbidity, na.rm=T))
)
rad_2 = data.frame(ph = c(max(df_0$ph, na.rm = T),0,mean(df_0$ph, na.rm=T)),
Hardness = c(max(df_0$Hardness),0,mean(df_0$Hardness, na.rm=T)),
Solids = c(max(df_0$Solids),0,mean(df_0$Solids, na.rm=T)),
Chloramines = c(max(df_0$Chloramines),0,mean(df_0$Chloramines, na.rm=T)),
Sulfate = c(max(df_0$Sulfate, na.rm = T),0,mean(df_0$Sulfate, na.rm=T)),
Conductivity = c(max(df_0$Conductivity),0,mean(df_0$Conductivity, na.rm=T)),
Organic_Carbon = c(max(df_0$Organic_carbon),0,mean(df_0$Organic_carbon, na.rm=T)),
Trihalomethanes = c(max(df_0$Trihalomethanes,na.rm=T),0,mean(df_0$Trihalomethanes, na.rm=T)),
Turbidity = c(max(df_0$Turbidity),0,mean(df_0$Turbidity, na.rm=T))
)
# Color vector
colors_border=c( rgb(0.2,0.5,0.5,0.9), rgb(0.8,0.2,0.5,0.9) , rgb(0.7,0.5,0.1,0.9) )
colors_in=c( rgb(0.2,0.5,0.5,0.4), rgb(0.8,0.2,0.5,0.4) , rgb(0.7,0.5,0.1,0.4) )
radarchart(rad_1  , axistype=1 ,
#custom polygon
pcol=colors_border , pfcol=colors_in , plwd=4 , plty=1,
#custom the grid
cglcol="grey", cglty=1, axislabcol="grey", cglwd=0.8,
#custom labels
vlcex=0.8 , title = "Potable Water"
)
radarchart(rad_2  , axistype=1 ,
#custom polygon
pcol=colors_border , pfcol=colors_in , plwd=4 , plty=1,
#custom the grid
cglcol="grey", cglty=1, axislabcol="grey", cglwd=0.8,
#custom labels
vlcex=0.8 , title = "Not Potable Water"
)
new_rad = data.frame(ph = c(max(df$ph, na.rm = T),0,mean(df_0$ph, na.rm=T),mean(df_1$ph, na.rm=T)),
Hardness = c(max(df_0$Hardness),0,mean(df_0$Hardness, na.rm=T),mean(df_1$Hardness, na.rm=T)),
Solids = c(max(df_0$Solids),0,mean(df_0$Solids, na.rm=T),mean(df_1$Solids, na.rm=T)),
Chloramines = c(max(df_0$Chloramines),0,mean(df_0$Chloramines, na.rm=T),mean(df_1$Chloramines, na.rm=T)),
Sulfate = c(max(df_0$Sulfate, na.rm = T),0,mean(df_0$Sulfate, na.rm=T),mean(df_1$Sulfate, na.rm=T)),
Conductivity = c(max(df_0$Conductivity),0,mean(df_0$Conductivity, na.rm=T),mean(df_1$Conductivity, na.rm=T)),
Organic_Carbon = c(max(df_0$Organic_carbon),0,mean(df_0$Organic_carbon, na.rm=T),mean(df_1$Organic_carbon, na.rm=T)),
Trihalomethanes = c(max(df_0$Trihalomethanes,na.rm=T),0,mean(df_0$Trihalomethanes, na.rm=T),mean(df_1$Trihalomethanes,na.rm=T)),
Turbidity = c(max(df_0$Turbidity),0,mean(df_0$Turbidity, na.rm=T),mean(df_1$Turbidity, na.rm=T))
)
row.names(new_rad)[3:4] = c("Not Potable", "Potable")
# Color vector
colors_border=c( rgb(0.2,0.5,0.5,0.9), rgb(0.8,0.2,0.5,0.9) )
colors_in=c( rgb(0.2,0.5,0.5,0.4), rgb(0.8,0.2,0.5,0.4))
# plot with default options:
radarchart( new_rad  , axistype=1 ,
#custom polygon
pcol=colors_border , pfcol=colors_in , plwd=4 , plty=1,
#custom the grid
cglcol="grey", cglty=1, axislabcol="grey", cglwd=0.8,
#custom labels
vlcex=0.8
)
# Add a legend
legend(x=0.7, y=1, legend = rownames(new_rad[-c(1,2),]), bty = "n", pch=20 , col=colors_in , text.col = "grey", cex=1.2, pt.cex=3)
new_rad
pheatmap(cor(df, use = "complete"), display_numbers = T,cluster_rows = F, cluster_cols = F, fontsize_number = 15)
gg_miss_var(df, show_pct = TRUE)
library(missRanger)
library(dlookr)
plot_na_intersect(df)
plot_na_pareto(df)
md.pattern(df,rotate.names = TRUE, plot=TRUE)
library(visdat)
vis_miss(df)
set.seed(1)
df$Potability = as.factor(df$Potability) ### changing our Potability variables into a factor since it's a category !
train.index = createDataPartition(df$Potability, p = .6, list = FALSE)
train.set = df[ train.index,] ### 60%
test.set= df[-train.index,] ### 40% test
head(train.set)
set.seed(1)
tr_control = trainControl(method = "cv",number = 5 ,summaryFunction =  multiClassSummary) # Setting 5 fold cross-validation
normal_cv_tree = train(Potability ~ ., #. is to tell that we use all our variables as predictors on personal loan
data = train.set,    ## on our training data
method = "rpart",    ### we use classification tree
na.action = na.pass,
preProcess = c("center","scale"),
trControl = tr_control)   ### the cross validation on 10 folds  ### on 30 k
#,metric = "Kappa"# We can play with metrics to select one specific but here I want them all
print(normal_cv_tree)
accu1 = max(normal_cv_tree$results$Accuracy)
f11 = max(normal_cv_tree$results$F1)
#results = data.frame("Accuracy" = accu1, )
set.seed(1) ### To have the same results  !!!
tr_control = trainControl(method = "cv",number = 5 ,summaryFunction =  multiClassSummary) ### use cross validation 10 times on 10 different fold and have a summary of all metrics and having a preprocess step of imputing the median to see if it works well
median_cv_tree = train(Potability ~ ., #. is to tell that we use all our variables as predictors on personal loan
data = train.set,    ## on our training data
method = "rpart",    ### we use classification tree
na.action = na.pass,
trControl = tr_control,
preProcess = c("medianImpute","center","scale"))   ### the cross validation on 10 folds  ### on 30 k
#,metric = "Kappa"# We can play with metrics to select one specific but here I want them all
print(median_cv_tree)
med_acc = max(median_cv_tree$results$Accuracy)
med_f1 = max(median_cv_tree$results$F1)
set.seed(1)
tr_control = trainControl(method = "cv",number = 5 ,summaryFunction =  multiClassSummary)
knnimpute_cv_tree = train(Potability ~ ., #. is to tell that we use all our variables as predictors on personal loan
data = train.set,    ## on our training data
method = "rpart",    ### we use classification tree
na.action = na.pass,
trControl = tr_control,
preProcess = c("knnImpute","center","scale"))   ### the cross validation on 10 folds  ### on 30 k
#,metric = "Kappa"# We can play with metrics to select one specific but here I want them all
print(knnimpute_cv_tree)
knn_acc = max(knnimpute_cv_tree$results$Accuracy)
knn_f1 = max(knnimpute_cv_tree$results$F1)
set.seed(1) ### To have the same results  !!!
train.set2 = na.omit(train.set)
tr_control = trainControl(method = "cv",number = 5 ,summaryFunction =  multiClassSummary) ### use cross validation 10 times on 10 different fold and have a summary of all metrics and having a preprocess step of imputing the median to see if it works well
drop_cv_tree = train(Potability ~ ., #. is to tell that we use all our variables as predictors on personal loan
data = train.set2,    ## on our training data
method = "rpart",    ### we use classification tree
na.action = na.pass,
preProcess = c("center","scale"),
trControl = tr_control)   ### the cross validation on 10 folds  ### on 30 k
#,metric = "Kappa"# We can play with metrics to select one specific but here I want them all
print(drop_cv_tree)
drop_acc = max(drop_cv_tree$results$Accuracy)
drop_f1 = max(drop_cv_tree$results$F1)
results_cv_impute = data.frame("Accuracy" = c(accu1, med_acc, knn_acc, drop_acc), "F1 Score" = c(f11, med_f1, knn_f1, drop_f1),"Method" = c("No dropping","Median imputation","K-NN imputation","Dropping the NAs"))
results_cv_impute %>% gather(Attributes, Values, 1:2) %>% ggplot(aes(x = Attributes, y = Values, fill = Method)) + scale_fill_viridis_d() + geom_bar(stat = "identity",position = "dodge") + geom_text(mapping= aes(x = Attributes, y=Values,label = round(Values,4)), vjust=-0.5, size = 2,position = position_dodge(width = .9), col = "red") + labs(title = "Comparison of the methods to deal with the NAs", x = "Metrics") + theme_light()
range_values = preProcess(train.set, method = c("knnImpute", "range")) ### range method that we will use for neural nets and knn mostly
train.range = predict(range_values, train.set)
test.range = predict(range_values, test.set)
norm_values = preProcess(train.set, method = c("knnImpute", "center","scale")) ### z score method (-mean / sd)
train.norm = predict(norm_values, train.set)
test.norm = predict(norm_values, test.set)
#test = train.set
#norm_values = preProcess(train.set, method = c("range"))
#test_set = predict(norm_values, test)
scale_back_z_score <- function(z,var) {
sd_train = sd(train.set[,var], na.rm = T)
mean_train = mean(train.set[,var], na.rm = T)
x = sapply(z, function(x_) x_*sd_train + mean_train)
return(x)
}
train_scaled_back = train.norm
test_scaled_back = test.norm
#colnames(train.norm[-10]) Could do this to scale back our data
for (i in colnames(train_scaled_back[-10])) {
train_scaled_back[i] = scale_back_z_score(train_scaled_back[i],i)
}
for (i in colnames(test_scaled_back[-10])) {
test_scaled_back[i] = scale_back_z_score(test_scaled_back[i],i)
}
library(reshape2)
ph_group = cbind(train.set$ph, train_scaled_back$ph)
ph_group = as.data.frame(ph_group)
colnames(ph_group) = c("ph no imputation", "ph knn imputation")
ph_group = melt(ph_group)
diff_ph = ggplot(ph_group, aes(x=value, group = variable, fill = variable)) + geom_density(alpha = 0.5)+labs(title = "Distribution of PH with and without knn imputation") + scale_fill_manual(values = c("red","blue"))
sulfate_group = cbind(train.set$Sulfate, train_scaled_back$Sulfate)
sulfate_group = as.data.frame(sulfate_group)
colnames(sulfate_group) = c("sulfate no imputation", "sulfate knn imputation")
sulfate_group = melt(sulfate_group)
diff_sulfate = ggplot(sulfate_group, aes(x=value, group = variable, fill = variable)) + geom_density(alpha = 0.5)+labs(title = "Distribution of sulfate with and without knn imputation") + scale_fill_manual(values = c("red","blue"))
trihalomethanes_group = cbind(train.set$Trihalomethanes, train_scaled_back$Trihalomethanes)
trihalomethanes_group = as.data.frame(trihalomethanes_group)
colnames(trihalomethanes_group) = c("trihalomethanes no imputation", "trihalomethanes knn imputation")
trihalomethanes_group = melt(trihalomethanes_group)
diff_triha = ggplot(trihalomethanes_group, aes(x=value, group = variable, fill = variable)) + geom_density(alpha = 0.5)+labs(title = "Distribution of trihalomethanes with and without knn imputation") + scale_fill_manual(values = c("red","blue"))
plot_grid(diff_ph, diff_sulfate, diff_triha)
fig <- plot_ly(train_scaled_back, x = ~ph, y = ~Turbidity, z = ~Organic_carbon, color = ~Potability)
fig <- fig %>% add_markers()
fig <- fig %>% layout(scene = list(xaxis = list(title = 'ph'),
yaxis = list(title = 'Turbidity'),
zaxis = list(title = 'Organic_carbon')))
fig
set.seed(1)
tr_control = trainControl(method = "cv",number = 5 ,summaryFunction =  multiClassSummary) # 5 fold CV
knn_cross_val = train(Potability ~ ., # Predicted class
data = train_scaled_back,    # on our training data
method = "knn",    # we use knn
trControl = tr_control,
preProcess="range", # preProcess our data with the range method for every fold
tuneGrid = data.frame(k = seq(50)))
print(knn_cross_val)
knn_cv_acc = knn_cross_val$results[max(knn_cross_val$results$Accuracy) == knn_cross_val$results$Accuracy, c("k","Accuracy")]$Accuracy
knn_cv_acc
knn_cross_val$resample$Accuracy
set.seed(1)
library(class)
knn_res = knn(train.range[-10], test.range[-10], cl=train.range$Potability,k=18, prob = T)
confusion_knn = confusionMatrix(knn_res, test.range$Potability,positive = "1")
confusion_knn
accuracy_knn = confusion_knn$overall["Accuracy"]
colours = c("#599ad3", "#f9a65a")
res_knn = data.frame("Accuracy" = c(knn_cv_acc, accuracy_knn), "Sets"=c("avg cross-validation","test"))
ggplot(res_knn, aes(x=Sets, y=Accuracy, fill = Sets)) + geom_bar(stat = "identity") + labs(title = "Accuracy CV using training set VS test set") + scale_fill_manual(values = colours) + geom_text(mapping= aes(x = Sets, y=Accuracy,label = round(Accuracy,4)), vjust=-0.5, size = 2, col = "red")
set.seed(1)
train_tree = rpart(Potability ~ . , data=train_scaled_back, method = "class", control=rpart.control(maxdepth=30,cp=0, minsplit = 1,minbucket = 1, xval = 5))
library(rattle)
prune_cp.index = which.min(train_tree$cptable[,"xerror"])
prune_cp = train_tree$cptable[prune_cp.index,"CP"]
prune_cp #  0.007822686 CP
pruned_train_tree <- prune(train_tree, cp = prune_cp)
fancyRpartPlot(pruned_train_tree)
### CV train accuracy :
classificationtree_train_predict = predict(pruned_train_tree, train_scaled_back , type = "class")
confusionMatrix(classificationtree_train_predict, train_scaled_back$Potability, positive = "1")
#### test accuracy
classificationtree_test_predict = predict(pruned_train_tree, test_scaled_back , type = "class")
classificationtree_test_proba = predict(pruned_train_tree, test_scaled_back , type = "prob")[,2]
confusion_tree = confusionMatrix(classificationtree_test_predict, test_scaled_back$Potability, positive = "1")
confusion_tree
accuracy_tree = confusion_tree$overall["Accuracy"]
train_tree_acc = confusionMatrix(classificationtree_train_predict, train_scaled_back$Potability, positive = "1")$overall["Accuracy"]
colours = c("#599ad3", "#f9a65a")
tree_res = data.frame("Accuracy" = c(train_tree_acc, accuracy_tree), "Sets"=c("CV pruned tree train","pruned tree test"))
ggplot(tree_res, aes(x=Sets, y=Accuracy, fill = Sets)) + geom_bar(stat = "identity") + labs(title = "Accuracy CV using training set VS test set") + scale_fill_manual(values = colours) + geom_text(mapping= aes(x = Sets, y=Accuracy,label = round(Accuracy,4)), vjust=-0.5, size = 2, col = "red")
library(e1071)
nbayes.model = naiveBayes(Potability ~ ., data = train_scaled_back)
nbayes.predict = predict(nbayes.model, test_scaled_back)
nbayes_predict_proba = predict(nbayes.model, test_scaled_back,type = "raw")[,2]
confusion_nb = confusionMatrix(nbayes.predict, test_scaled_back$Potability, positive = "1")
accuracy_nb = confusion_nb$overall["Accuracy"]
confusion_nb
accuracy_nb
confusionMatrix(predict(nbayes.model, train_scaled_back), train_scaled_back$Potability, positive = "1")
set.seed(1)
tr_control = trainControl(method = "cv",number = 5) # 5 fold CV
nb_cv = train(Potability ~ ., # Predicted class
data = train_scaled_back,    # on our training data
method = "nb",    # we use knn
trControl = tr_control,
)
confusionMatrix(nb_cv)
nb_cv_acc = nb_cv$results[1,"Accuracy"]
#knn_cv_acc = knn_cross_val$results[max(knn_cross_val$results$Accuracy) == knn_cross_val$results$Accuracy, #c("k","Accuracy")]$Accuracy
#knn_cv_acc
#knn_cross_val$resample$Accuracy
colours = c("#599ad3", "#f9a65a")
nb_res = data.frame("Accuracy" = c(nb_cv_acc, accuracy_nb), "Sets"=c("Avg 5 fold CV train","test"))
ggplot(nb_res, aes(x=Sets, y=Accuracy, fill = Sets)) + geom_bar(stat = "identity") + labs(title = "Accuracy CV using training set VS test set") + scale_fill_manual(values = colours) + geom_text(mapping= aes(x = Sets, y=Accuracy,label = round(Accuracy,4)), vjust=-0.5, size = 2, col = "red")
set.seed(1)
library(fastAdaboost)
library(adabag)
tr_control = trainControl(method = "cv",number = 5 ,summaryFunction =  multiClassSummary)
boosted_cv = train(Potability ~ ., #. is to tell that we use all our variables as predictors on personal loan
data = train_scaled_back,    ## on our training data
method = "adaboost",    ### we use classification tree
trControl = tr_control)
print(boosted_cv)
set.seed(1)
cv_boost_acc = 0.6337712
test_predict_boost = predict(boosted_cv, test_scaled_back)
test_predict_boost_proba = predict(boosted_cv, test_scaled_back , type = "prob")[,2]
confusion_boost = confusionMatrix(as.factor(test_predict_boost), test_scaled_back$Potability, positive = "1")
confusion_boost
accuracy_boost = confusion_boost$overall["Accuracy"]
plot(varImp(boosted_cv), main="Variable Importance with boosting")
colours = c("#599ad3", "#f9a65a")
boost_res = data.frame("Accuracy" = c(cv_boost_acc, accuracy_boost), "Sets"=c("Avg 5 fold CV train","test"))
ggplot(boost_res, aes(x=Sets, y=Accuracy, fill = Sets)) + geom_bar(stat = "identity") + labs(title = "Accuracy CV using training set VS test set") + scale_fill_manual(values = colours) + geom_text(mapping= aes(x = Sets, y=Accuracy,label = round(Accuracy,4)), vjust=-0.5, size = 2, col = "red")
set.seed(1)
tr_control = trainControl(method = "cv",number = 5 ,summaryFunction =  multiClassSummary)
bagged_cv = train(Potability ~ ., #. is to tell that we use all our variables as predictors on personal loan
data = train_scaled_back,    ## on our training data
method = "treebag",    ### we use classification tree
nbagg = 200,
trControl = tr_control
)
print(bagged_cv)
cv_bagged_acc = bagged_cv$results$Accuracy
plot(varImp(bagged_cv), main="Variable Importance with Bagging")
set.seed(1)
test_predict_bag = predict(bagged_cv, test_scaled_back , type = "raw")
test_predict_bag_prob = predict(bagged_cv, test_scaled_back , type = "prob")[,2]
### to get the class, we need to use $class
#valid_predict_boost
confusion_bag = confusionMatrix(as.factor(test_predict_bag), test_scaled_back$Potability, positive = "1")
confusion_bag
accuracy_bag = confusion_bag$overall["Accuracy"]
colours = c("#599ad3", "#f9a65a")
bag_res = data.frame("Accuracy" = c(cv_bagged_acc, accuracy_bag), "Sets"=c("Avg 5 fold CV train","test"))
ggplot(bag_res, aes(x=Sets, y=Accuracy, fill = Sets)) + geom_bar(stat = "identity") + labs(title = "Accuracy CV using training set VS test set") + scale_fill_manual(values = colours) + geom_text(mapping= aes(x = Sets, y=Accuracy,label = round(Accuracy,4)), vjust=-0.5, size = 2, col = "red")
library(randomForest)
set.seed(1)
control = trainControl(method='cv',
number=5,
search='grid')
tunegrid = expand.grid(.mtry = (1:9))
rf_gridsearch = train(Potability ~ .,
data = train_scaled_back,
method = 'rf',
metric = 'Accuracy',
tuneGrid = tunegrid,
trControl = control,
importance = T)
print(rf_gridsearch)
library(randomForest)
rf_cv_acc = 0.6597099
set.seed(1)
randomf = randomForest(Potability~., data = train_scaled_back,mtry = 6, importance = T )
test_predict_rf = predict(randomf, test_scaled_back , type = "class")
test_predict_rf_proba = predict(randomf, test_scaled_back , type = "prob")[,2]
confusion_rf = confusionMatrix(as.factor(test_predict_rf), test_scaled_back$Potability, positive = "1")
confusion_rf
accuracy_rf = confusion_rf$overall["Accuracy"]
varImpPlot(randomf)
colours = c("#599ad3", "#f9a65a")
rf_res = data.frame("Accuracy" = c(rf_cv_acc, accuracy_rf), "Sets"=c("Avg 5 fold CV train","test"))
ggplot(rf_res, aes(x=Sets, y=Accuracy, fill = Sets)) + geom_bar(stat = "identity") + labs(title = "Accuracy CV using training set VS test set") + scale_fill_manual(values = colours) + geom_text(mapping= aes(x = Sets, y=Accuracy,label = round(Accuracy,4)), vjust=-0.5, size = 2, col = "red")
set.seed(1)
train_control = trainControl(method = "cv", number = 5)
# train the model on training set
logi_cv = train(Potability ~.,
data = train_scaled_back,
trControl = train_control,
method = "glm",
family=binomial())
# print cv scores
summary(logi_cv)
print(logi_cv)
confusionMatrix(logi_cv)
logi_cv_acc = logi_cv$results$Accuracy
pred.logit.reg = predict(logi_cv, test_scaled_back[,-10], type = "prob")[,2]
logi_pred_class = predict(logi_cv, test_scaled_back[,-10], type = "raw")
confusion_logi = confusionMatrix(predict(logi_cv, test_scaled_back), test_scaled_back$Potability, positive = "1")
confusion_logi
accuracy_logi = confusion_logi$overall["Accuracy"]
#library(devtools)
#devtools::install_github('cttobin/ggthemr')
ConfusionMatrixInfo <- function( data, predict, actual, cutoff )
{
# extract the column ;
# relevel making 1 appears on the more commonly seen position in
# a two by two confusion matrix
predict <- data[[predict]]
actual  <- relevel( as.factor( data[[actual]] ), "1" )
result <- data.table( actual = actual, predict = predict )
# caculating each pred falls into which category for the confusion matrix
result[ , type := ifelse( predict >= cutoff & actual == 1, "TP",
ifelse( predict >= cutoff & actual == 0, "FP",
ifelse( predict <  cutoff & actual == 1, "FN", "TN" ) ) ) %>% as.factor() ]
# jittering : can spread the points along the x axis
plot <- ggplot( result, aes( actual, predict, color = type ) ) +
geom_violin( fill = "white", color = NA ) +
geom_jitter( shape = 1 ) +
geom_hline( yintercept = cutoff, color = "blue", alpha = 0.6 ) +
scale_y_continuous( limits = c( 0, 1 ) ) +
scale_color_discrete( breaks = c( "TP", "FN", "FP", "TN" ) ) + # ordering of the legend
guides( col = guide_legend( nrow = 2 ) ) + # adjust the legend to have two rows
ggtitle( sprintf( "Confusion Matrix with Cutoff at %.2f", cutoff ) )
return( list( data = result, plot = plot ) )
}
library(data.table)
library(ggthemr)
logi_data = data.frame("prediction" = predict(logi_cv, test_scaled_back[,-10], type = "prob")[,2], "True" = test_scaled_back$Potability )
cm_info <- ConfusionMatrixInfo( data = logi_data, predict = "prediction",
actual = "True", cutoff = .5 )
ggthemr("flat")
cm_info$plot
colours = c("#599ad3", "#f9a65a")
logi_res = data.frame("Accuracy" = c(logi_cv_acc, accuracy_logi), "Sets"=c("Avg 5 fold CV train","test"))
ggplot(logi_res, aes(x=Sets, y=Accuracy, fill = Sets)) + geom_bar(stat = "identity") + labs(title = "Accuracy CV using training set VS test set") + scale_fill_manual(values = colours) + geom_text(mapping= aes(x = Sets, y=Accuracy,label = round(Accuracy,4)), vjust=-0.5, size = 2, col = "red")
set.seed(1)
control <- trainControl(method='cv',
number=5)
neural.net_cv <- train(Potability ~ ., data = train_scaled_back,
method = "nnet",  trControl = control, preProcess = "range")
neural.net_cv$bestTune
neural.net_cv
nn_cv_acc = max(neural.net_cv$results$Accuracy)
confusionMatrix(neural.net_cv)
nn_predict = predict(neural.net_cv$finalModel, test.range, type = "class")
nn_predict_proba = predict(neural.net_cv$finalModel, test.range, type = "raw")
confusion_nn_cv =confusionMatrix(as.factor(nn_predict), test.range$Potability, positive = "1")
confusion_nn_cv
accuracy_nn = confusionMatrix(as.factor(nn_predict), test.range$Potability, positive = "1")$overall["Accuracy"]
#train_predict_nn = predict(neural.net_cv, train.range) #Check if we were overfitting but not at all !
#confusionMatrix(train_predict_nn, train.range$Potability, positive = "1")
colours = c("#599ad3", "#f9a65a")
nn_res = data.frame("Accuracy" = c(nn_cv_acc, accuracy_nn), "Sets"=c("Avg 5 fold CV train","test"))
ggplot(nn_res, aes(x=Sets, y=Accuracy, fill = Sets)) + geom_bar(stat = "identity") + labs(title = "Accuracy CV using training set VS test set") + scale_fill_manual(values = colours) + geom_text(mapping= aes(x = Sets, y=Accuracy,label = round(Accuracy,4)), vjust=-0.5, size = 2, col = "red")
accuracy_all = data.frame("Model" =
c("K-NN","Naive-Bayes","logistic","Decision_tree","Bagging","Boosting","Random_forest","Neural_nets"),
"Accuracy"=c(accuracy_knn, accuracy_nb, accuracy_logi, accuracy_tree, accuracy_bag, accuracy_boost, accuracy_rf, accuracy_nn))
ggplot(accuracy_all, aes(x=Model, y = Accuracy, fill = Accuracy)) + geom_bar(width = 0.8,stat="identity") + scale_fill_viridis_c() + geom_text(mapping= aes(x = Model, y=Accuracy,label = round(Accuracy,4)), vjust=-0.5, size = 2, col = "red") + labs(title = "Accuracy of our models on the Test set")  + theme_pubr()+theme(axis.text.x = element_text(angle=90, vjust=1))
library(ggpubr)
accuracy_all = data.frame("Model" =
c("K-NN","Naive-Bayes","logistic","Decision_tree","Bagging","Boosting","Random_forest","Neural_nets"),
"Accuracy"=c(accuracy_knn, accuracy_nb, accuracy_logi, accuracy_tree, accuracy_bag, accuracy_boost, accuracy_rf, accuracy_nn))
ggplot(accuracy_all, aes(x=Model, y = Accuracy, fill = Accuracy)) + geom_bar(width = 0.8,stat="identity") + scale_fill_viridis_c() + geom_text(mapping= aes(x = Model, y=Accuracy,label = round(Accuracy,4)), vjust=-0.5, size = 2, col = "red") + labs(title = "Accuracy of our models on the Test set")  + theme_pubr()+theme(axis.text.x = element_text(angle=90, vjust=1))
proba_weird = attr(knn_res,"prob") # Returns only the highest proba so I will compare the proba to the outcome to find if it's the proba of being 1 or 0 ...
proba_new_knn = proba_weird + as.numeric(as.character(knn_res))
#proba_new_knn
proba_knn = ifelse(proba_new_knn > 1, proba_new_knn-1, 1-proba_new_knn)
results_all = data.frame("KNN_pred" = knn_res, "KNN_prob" = proba_knn, "logi_pred"=logi_pred_class, "logi_prob" = pred.logit.reg, "NB_pred" = nbayes.predict, "NB_prob" = nbayes_predict_proba, "CT_pred" = classificationtree_test_predict,"CT_prob" = classificationtree_test_proba, "bag_pred" = test_predict_bag, "bag_prob" = test_predict_bag_prob, "boost_pred" =test_predict_boost, "boost_prob" = test_predict_boost_proba, "rf_pred" = test_predict_rf, "rf_prob" = test_predict_rf_proba, "neural_net_pred"=nn_predict, "neural_net_prob" = nn_predict_proba)
head(results_all)
### Average prediction : WE have 8 models : knn, logi, naive bayes, CT, bag, boost, rf, neural net
ensemble_pred = as.numeric(as.character(results_all$KNN_pred)) + as.numeric(as.character(results_all$logi_pred)) + as.numeric(as.character(results_all$NB_pred)) + as.numeric(as.character(results_all$CT_pred)) +
as.numeric(as.character(results_all$bag_pred)) + as.numeric(as.character(results_all$boost_pred)) + as.numeric(as.character(results_all$rf_pred)) + as.numeric(as.character(results_all$neural_net_pred))
ensemble_majority = ifelse(ensemble_pred>= 4,1,0)
results_all$ensemble_majority = ensemble_majority
### Average proba :
results_all$ensemble_proba = ifelse((results_all$KNN_prob +  results_all$logi_prob +  results_all$NB_prob +  results_all$CT_prob +  results_all$bag_prob +  results_all$boost_prob +  results_all$rf_prob +  results_all$neural_net_prob)/8 >= 0.5, 1,0)
results_all$true = test_scaled_back$Potability
confu_majority = confusionMatrix(as.factor(results_all$ensemble_majority), test_scaled_back$Potability,positive = "1")
confu_majority
confu_avg_proba = confusionMatrix(as.factor(results_all$ensemble_proba), test_scaled_back$Potability,positive = "1")
confu_avg_proba
acc_majority = confu_majority$overall["Accuracy"]
acc_avg_proba = confu_avg_proba$overall["Accuracy"]
ensemble_df = data.frame("Accuracy"=c(acc_majority,acc_avg_proba),"Ensemble"=c("Majority","Average Proba"))
ggplot(ensemble_df, aes(x = Ensemble, y=Accuracy, fill = Ensemble)) + geom_bar(stat="identity") + geom_text(mapping= aes(x = Ensemble, y=Accuracy,label = round(Accuracy,4)), vjust=-0.5, size = 2, col = "red") + labs(title = "Accuracy of our Ensemble models on the Test set") + theme_bw()
View(df)
View(df)
new_rad = data.frame(ph = c(max(df$ph, na.rm = T),0,mean(df_0$ph, na.rm=T),mean(df_1$ph, na.rm=T)),
Hardness = c(max(df_0$Hardness),0,mean(df_0$Hardness, na.rm=T),mean(df_1$Hardness, na.rm=T)),
Solids = c(max(df_0$Solids),0,mean(df_0$Solids, na.rm=T),mean(df_1$Solids, na.rm=T)),
Chloramines = c(max(df_0$Chloramines),0,mean(df_0$Chloramines, na.rm=T),mean(df_1$Chloramines, na.rm=T)),
Sulfate = c(max(df_0$Sulfate, na.rm = T),0,mean(df_0$Sulfate, na.rm=T),mean(df_1$Sulfate, na.rm=T)),
Conductivity = c(max(df_0$Conductivity),0,mean(df_0$Conductivity, na.rm=T),mean(df_1$Conductivity, na.rm=T)),
Organic_Carbon = c(max(df_0$Organic_carbon),0,mean(df_0$Organic_carbon, na.rm=T),mean(df_1$Organic_carbon, na.rm=T)),
Trihalomethanes = c(max(df_0$Trihalomethanes,na.rm=T),0,mean(df_0$Trihalomethanes, na.rm=T),mean(df_1$Trihalomethanes,na.rm=T)),
Turbidity = c(max(df_0$Turbidity),0,mean(df_0$Turbidity, na.rm=T),mean(df_1$Turbidity, na.rm=T))
)
row.names(new_rad)[3:4] = c("Non-potable", "Potable")
# Color vector
colors_border=c( rgb(0.2,0.5,0.5,0.9), rgb(0.8,0.2,0.5,0.9) )
colors_in=c( rgb(0.2,0.5,0.5,0.4), rgb(0.8,0.2,0.5,0.4))
# plot with default options:
radarchart( new_rad  , axistype=1 ,
#custom polygon
pcol=colors_border , pfcol=colors_in , plwd=4 , plty=1,
#custom the grid
cglcol="grey", cglty=1, axislabcol="grey", cglwd=0.8,
#custom labels
vlcex=0.8
)
# Add a legend
legend(x=0.7, y=1, legend = rownames(new_rad[-c(1,2),]), bty = "n", pch=20 , col=colors_in , text.col = "grey", cex=1.2, pt.cex=3)
new_rad
